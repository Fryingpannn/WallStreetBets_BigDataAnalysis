{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WallStreetBets-CountVec-NaiveBayes.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCK3YmBuXKSV","executionInfo":{"status":"ok","timestamp":1618276945457,"user_tz":240,"elapsed":10952,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"4889b466-fda0-431c-af37-2a46407c75c6"},"source":["!pip install numpy\n","!pip install matplotlib\n","!pip install scikit-learn\n","!pip install pyspark"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A8nXPXUBYJK4"},"source":["from pyspark.rdd import RDD\n","from pyspark.sql import Row\n","from pyspark.sql import DataFrame\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import lit\n","from pyspark.sql.functions import desc\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.recommendation import ALS\n","from pyspark import SparkContext as sc\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import udf,col\n","import os\n","# tools\n","import re\n","import math\n","import json\n","import requests\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import time\n","from datetime import datetime, timedelta\n","import string\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BpfULFl8ZF95"},"source":["from pyspark.ml.classification import NaiveBayes\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","#from pyspark.sql.functions import split as splitsp\n","from pyspark.ml.feature import CountVectorizer\n","from pyspark.ml.feature import StopWordsRemover\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml.evaluation import ClusteringEvaluator\n","\n","# %matplotlib inline\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from mpl_toolkits.mplot3d import Axes3D\n","\n","# from pyspark.mllib.linalg import Vectors\n","# from pyspark.mllib.linalg.distributed import RowMatrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mSdK4WiaZJoO"},"source":["def init_spark():\n","    spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Python Spark Naive Bayes CountVectorizer\") \\\n","        .getOrCreate()\n","    return spark\n","spark = init_spark()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jrMOC8X5Zk5p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618276953529,"user_tz":240,"elapsed":18991,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"0b154e49-22ac-453b-8fe8-cdfbc39c7849"},"source":["'''\n","Read Lemma data\n","'''\n","from pyspark.sql.types import ArrayType\n","from pyspark.sql.types import StringType\n","from pyspark.sql.types import IntegerType\n","\n","data = spark.read.csv(\"lemma-100days-wsbdata.csv\", header=True)\n","function_array = udf(lambda r: r.split(\"|\"), ArrayType(StringType()))\n","function_toNumerical = udf(lambda r: int(r), IntegerType())\n","text_lemmas = data.withColumn('finished_lemmas', function_array('text')).drop('text').withColumn('label', function_toNumerical('label'))\n","print(text_lemmas.count())\n","text_lemmas.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1144\n","+------+-----+--------------------+\n","|    id|label|     finished_lemmas|\n","+------+-----+--------------------+\n","|ks1tzw|    0|[all, right, all,...|\n","|ksjhuu|    0|[bldr, $, pt, pos...|\n","|kt79b2|    0|[we, might, be, h...|\n","|kt9enf|    0|[bear, feast, on,...|\n","|ktbu75|    0|[so, today, i, go...|\n","|ktfori|    0|[what, a, week, i...|\n","|kup2e2|    1|[start, to, feel,...|\n","|kurzyz|    0|[i, honestly, don...|\n","|kusng4|    0|[soi, recently, o...|\n","|kuku2g|    1|[nio, be, disrupt...|\n","|kutslm|    1|[listen, up, you,...|\n","|kv7k8k|    0|[have, anyone, no...|\n","|kvarzs|    0|[now, that, the, ...|\n","|kvcard|    0|[we, all, know, t...|\n","|kvcmhk|    1|[it, do, not, dil...|\n","|kva2kt|    0|[we, know, you, l...|\n","|kvacad|    1|[so, i, hear, you...|\n","|kvcimd|    1|[look, at, hour, ...|\n","|kvtk4b|    1|[giga, berain, co...|\n","|kw2vwm|    1|[see, the, end, o...|\n","+------+-----+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n_L9lrQrolKo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618276954676,"user_tz":240,"elapsed":20129,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"5c5b0f75-e822-46d2-bc3a-775642926a85"},"source":["'''\n","Get the Corpus.\n","Removing stop words from the text lemmas. \n","'''\n","remover = StopWordsRemover(inputCol=\"finished_lemmas\", outputCol=\"text\")\n","filtered_df = remover.transform(text_lemmas)\n","filtered_df.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+------+-----+--------------------+--------------------+\n","|    id|label|     finished_lemmas|                text|\n","+------+-----+--------------------+--------------------+\n","|ks1tzw|    0|[all, right, all,...|[right, artist, f...|\n","|ksjhuu|    0|[bldr, $, pt, pos...|[bldr, $, pt, pos...|\n","|kt79b2|    0|[we, might, be, h...|[might, hear, fir...|\n","|kt9enf|    0|[bear, feast, on,...|[bear, feast, low...|\n","|ktbu75|    0|[so, today, i, go...|[today, go, games...|\n","|ktfori|    0|[what, a, week, i...|[week, steel, big...|\n","|kup2e2|    1|[start, to, feel,...|[start, feel, rea...|\n","|kurzyz|    0|[i, honestly, don...|[honestly, dont, ...|\n","|kusng4|    0|[soi, recently, o...|[soi, recently, o...|\n","|kuku2g|    1|[nio, be, disrupt...|[nio, disrupt, te...|\n","|kutslm|    1|[listen, up, you,...|[listen, degenera...|\n","|kv7k8k|    0|[have, anyone, no...|[anyone, notice, ...|\n","|kvarzs|    0|[now, that, the, ...|[boy, rc, get, po...|\n","|kvcard|    0|[we, all, know, t...|[know, ðŸŒˆðŸ»s, cal...|\n","|kvcmhk|    1|[it, do, not, dil...|[dilute, share, d...|\n","|kva2kt|    0|[we, know, you, l...|[know, love, chew...|\n","|kvacad|    1|[so, i, hear, you...|[hear, degenerate...|\n","|kvcimd|    1|[look, at, hour, ...|[look, hour, char...|\n","|kvtk4b|    1|[giga, berain, co...|[giga, berain, co...|\n","|kw2vwm|    1|[see, the, end, o...|[see, end, video,...|\n","+------+-----+--------------------+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ROSiqgkmwGGu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618276958542,"user_tz":240,"elapsed":23988,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"e9ed603a-36c9-408a-9094-a74e5e2603fc"},"source":["'''\n","Create Document-Term Matrix by vectorizing the filtered text.\n","- returns the features column: (total nb of words, indices of each word in total vocab, count of each word)\n","'''\n","to_vectorize = filtered_df.select('id', 'label', 'text')\n","cv = CountVectorizer(inputCol=\"text\", outputCol=\"features\")\n","model_vec = cv.fit(to_vectorize)\n","result_vec = model_vec.transform(to_vectorize)\n","print(\"Total count of vocabulary:\", len(model_vec.vocabulary))\n","result_vec.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total count of vocabulary: 10932\n","+------+-----+--------------------+--------------------+\n","|    id|label|                text|            features|\n","+------+-----+--------------------+--------------------+\n","|ks1tzw|    0|[right, artist, f...|(10932,[1,2,4,7,8...|\n","|ksjhuu|    0|[bldr, $, pt, pos...|(10932,[3,5,6,7,9...|\n","|kt79b2|    0|[might, hear, fir...|(10932,[25,55,77,...|\n","|kt9enf|    0|[bear, feast, low...|(10932,[1,4,6,7,8...|\n","|ktbu75|    0|[today, go, games...|(10932,[1,4,8,25,...|\n","|ktfori|    0|[week, steel, big...|(10932,[3,4,5,7,8...|\n","|kup2e2|    1|[start, feel, rea...|(10932,[3,8,13,30...|\n","|kurzyz|    0|[honestly, dont, ...|(10932,[8,15,16,1...|\n","|kusng4|    0|[soi, recently, o...|(10932,[0,1,4,11,...|\n","|kuku2g|    1|[nio, disrupt, te...|(10932,[4,11,14,1...|\n","|kutslm|    1|[listen, degenera...|(10932,[4,5,11,12...|\n","|kv7k8k|    0|[anyone, notice, ...|(10932,[0,1,19,26...|\n","|kvarzs|    0|[boy, rc, get, po...|(10932,[1,5,6,8,1...|\n","|kvcard|    0|[know, ðŸŒˆðŸ»s, cal...|(10932,[0,1,3,4,5...|\n","|kvcmhk|    1|[dilute, share, d...|(10932,[0,17,25,4...|\n","|kva2kt|    0|[know, love, chew...|(10932,[1,8,17,18...|\n","|kvacad|    1|[hear, degenerate...|(10932,[4,5,14,16...|\n","|kvcimd|    1|[look, hour, char...|(10932,[16,20,22,...|\n","|kvtk4b|    1|[giga, berain, co...|(10932,[0,3,4,9,1...|\n","|kw2vwm|    1|[see, end, video,...|(10932,[3,4,10,11...|\n","+------+-----+--------------------+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mg1XXG03aAX3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618280768721,"user_tz":240,"elapsed":397,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"d8a984f5-c5a4-483a-f57d-02281308fcb1"},"source":["selectedData = result_vec.select('id', 'label','features', 'text')\n","selectedData.show(truncate=True)\n","TP = udf(lambda x,y: int(x==1 and y==1))\n","FP = udf(lambda x,y: int(x==1 and y==0))\n","FN = udf(lambda x,y: int(x==0 and y==1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+------+-----+--------------------+--------------------+\n","|    id|label|            features|                text|\n","+------+-----+--------------------+--------------------+\n","|ks1tzw|    0|(10932,[1,2,4,7,8...|[right, artist, f...|\n","|ksjhuu|    0|(10932,[3,5,6,7,9...|[bldr, $, pt, pos...|\n","|kt79b2|    0|(10932,[25,55,77,...|[might, hear, fir...|\n","|kt9enf|    0|(10932,[1,4,6,7,8...|[bear, feast, low...|\n","|ktbu75|    0|(10932,[1,4,8,25,...|[today, go, games...|\n","|ktfori|    0|(10932,[3,4,5,7,8...|[week, steel, big...|\n","|kup2e2|    1|(10932,[3,8,13,30...|[start, feel, rea...|\n","|kurzyz|    0|(10932,[8,15,16,1...|[honestly, dont, ...|\n","|kusng4|    0|(10932,[0,1,4,11,...|[soi, recently, o...|\n","|kuku2g|    1|(10932,[4,11,14,1...|[nio, disrupt, te...|\n","|kutslm|    1|(10932,[4,5,11,12...|[listen, degenera...|\n","|kv7k8k|    0|(10932,[0,1,19,26...|[anyone, notice, ...|\n","|kvarzs|    0|(10932,[1,5,6,8,1...|[boy, rc, get, po...|\n","|kvcard|    0|(10932,[0,1,3,4,5...|[know, ðŸŒˆðŸ»s, cal...|\n","|kvcmhk|    1|(10932,[0,17,25,4...|[dilute, share, d...|\n","|kva2kt|    0|(10932,[1,8,17,18...|[know, love, chew...|\n","|kvacad|    1|(10932,[4,5,14,16...|[hear, degenerate...|\n","|kvcimd|    1|(10932,[16,20,22,...|[look, hour, char...|\n","|kvtk4b|    1|(10932,[0,3,4,9,1...|[giga, berain, co...|\n","|kw2vwm|    1|(10932,[3,4,10,11...|[see, end, video,...|\n","+------+-----+--------------------+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n_HCQvC4lxel","colab":{"base_uri":"https://localhost:8080/","height":910},"executionInfo":{"status":"ok","timestamp":1618276958999,"user_tz":240,"elapsed":24432,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"95351c4a-2338-4e0c-9370-5e10a630709b"},"source":["'''\n","Separate data into training/test used for Naive-Bayes\n","'''\n","# training_zero, test_zero = selectedData.where(selectedData.label == 0).randomSplit([0.7, 0.3])\n","# training_one, test_one = selectedData.where(selectedData.label == 1).randomSplit([0.7, 0.3])\n","\n","# training = training_zero.union(training_one)\n","# test = test_zero.union(test_one)\n","# #training.show()\n","# # should be 70% of total in training, 30% in test\n","# print(\"Total data count:\", selectedData.count())\n","# print(\"Total count of >6%\", training.count())\n","# print(\"Total count of <6%\", test.count())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nSeparate data into training/test used for Naive-Bayes\\n'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"EILkKEvtCSat"},"source":["'''\n","Naive-Bayes following from CountVectorizer with K-fold cross-validation\n","'''\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.mllib.evaluation import BinaryClassificationMetrics\n","from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","\n","def NAIVEBAYES_CVKFOLD(smooth=0, model_type=0): \n","  # separating train/test data\n","  training_zero, test_zero = selectedData.where(selectedData.label == 0).randomSplit([0.7, 0.3])\n","  training_one, test_one = selectedData.where(selectedData.label == 1).randomSplit([0.7, 0.3])\n","\n","  training = training_zero.union(training_one)\n","  test = test_zero.union(test_one)\n","\n","\n","\n","  # create trainer with parameters then train\n","  # smoothing: smooth probabilities of 0 to the input\n","  #nb = NaiveBayes(smoothing=0.636768, modelType=\"complement\")\n","  nb = NaiveBayes(smoothing=smooth, modelType=model_type)\n","\n","  # Create ParamGrid for Cross Validation\n","  nbparamGrid = (ParamGridBuilder()\n","               .addGrid(nb.smoothing, [0.2684835187532758, 0.46961116193132335, 0.44860427414315174, 0.7649149741542184, 0.25609960046163693])\n","               .build())\n","  \n","  # evaluation\n","  #, metricName=\"accuracy\n","\n","  #evaluator = BinaryClassificationMetrics(labelCol=\"label\", predictionCol=\"prediction\")\n","  #evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","  #evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","  # Create 5-fold CrossValidator\n","  evaluator = BinaryClassificationEvaluator();\n","  nbcv = CrossValidator(estimator = nb,\n","                      estimatorParamMaps = nbparamGrid,\n","                      evaluator = evaluator,\n","                      numFolds = 5)\n","\n","  model_NBCV = nbcv.fit(training)\n","\n","  # display on test set: appends a prediction column\n","  predictions = model_NBCV.transform(test)\n","  predictionAndLabels = predictions.rdd.map(lambda row: (float(row.prediction), row.label))\n","\n","  accuracy = evaluator.evaluate(predictions)\n","  #metrics_multi = MulticlassMetrics(predictionAndLabels)\n","\n","  labels = predictions.rdd.map(lambda lp: lp.label).distinct().collect()\n","  #precision = metrics_multi.precision()\n","  #recall = metrics_multi.recall()\n","  #f1Score = metrics_multi.fMeasure()\n","  print(\"Summary Stats\")\n","  print('Model accuracy:', accuracy)\n","  #predictlabel_df = predictionAndLabels.toDF()\n","  #predictlabel_df\n","  \n","  prela_df = predictions.select(\"prediction\",\"label\")\n","  prela_df=prela_df.withColumn(\"TP\", TP(prela_df.prediction,prela_df.label))\n","  prela_df=prela_df.withColumn(\"FP\", FP(prela_df.prediction,prela_df.label))\n","  prela_df=prela_df.withColumn(\"FN\", FN(prela_df.prediction,prela_df.label))\n","  TP_ = prela_df.select(\"TP\").count()\n","  FP_ = prela_df.select(\"FP\").count()\n","  FN_ = prela_df.select(\"FN\").count()\n","  \n","  print(TP,FP,FN)\n","  precision = TP/(TP+FP)\n","  recall = TP/(TP+FN)\n","\n","  F1 = 2*(precision*recall)/(precision+recall)\n","  print(\"Precision:\",str(precision))\n","  print(\"Recall:\",str(recall))\n","  print(\"F1 Score:\",str(F1))\n","  return model_NBCV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKRfLM28EZYx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618280170846,"user_tz":240,"elapsed":63937,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"48afe26e-5bff-44a5-bba0-cc1e9f0bd5e4"},"source":["final_model_cv = NAIVEBAYES_CVKFOLD(model_type='multinomial')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Summary Stats\n","Model accuracy: 0.4610613810741688\n","354 354 354\n","Precision: 0.5\n","Recall: 0.5\n","F1 Score: 0.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C3W5XF4LSJM6"},"source":["'''\n","Naive-Bayes following from CountVectorizer\n","'''\n","def NAIVEBAYES_CV(smooth=0, model_type=0): \n","  # separating train/test data\n","  training_zero, test_zero = selectedData.where(selectedData.label == 0).randomSplit([0.7, 0.3])\n","  training_one, test_one = selectedData.where(selectedData.label == 1).randomSplit([0.7, 0.3])\n","\n","  training = training_zero.union(training_one)\n","  test = test_zero.union(test_one)\n","\n","  # create trainer with parameters then train\n","  # smoothing: smooth probabilities of 0 to the input\n","  #nb = NaiveBayes(smoothing=0.636768, modelType=\"complement\")\n","  nb = NaiveBayes(smoothing=smooth, modelType=model_type)\n","  model_NB = nb.fit(training)\n","\n","  # display on test set: appends a prediction column\n","  predictions = model_NB.transform(test)\n","  #predictions.show()\n","  prela_df = predictions.select(\"prediction\",\"label\")\n","  prela_df=prela_df.withColumn(\"TP\", TP(prela_df.prediction,prela_df.label))\n","  prela_df=prela_df.withColumn(\"FP\", FP(prela_df.prediction,prela_df.label))\n","  prela_df=prela_df.withColumn(\"FN\", FN(prela_df.prediction,prela_df.label))\n","\n","  #prela_df.select(\"TP\",\"FP\").map(lambda x: )\n","\n","  TP_ = prela_df.where(prela_df.TP==1).count()\n","  FP_ = prela_df.where(prela_df.FP==1).count()\n","  FN_ = prela_df.where(prela_df.FN==1).count()\n","\n","  print(TP_,FP_,FN_)\n","\n","  precision = TP_/(TP_+FP_)\n","  recall = TP_/(TP_+FN_)\n","  F1 = 2*(precision*recall)/(precision+recall)\n","\n","  # compute accuracy of on test set: compares labelCol and predictionCol\n","  evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","  accuracy = evaluator.evaluate(predictions)\n","  #print('Model accuracy:', accuracy)\n","  #print(accuracy,precision,recall,F1)\n","  return (accuracy,precision,recall,F1,model_NB)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXjd_oCODA6m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618281709409,"user_tz":240,"elapsed":6392,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"3e61a21d-d7d4-46eb-d2fe-13dac474746f"},"source":["acc,precision,recall,F1,modelNB = NAIVEBAYES_CV(0.2684835187532758,\"multinomial\")\n","print(\"Accuracy: \",acc)\n","print(\"Precision: \",precision)\n","print(\"Recall: \",recall)\n","print(\"F1 Score: \",F1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["96 55 92\n","Accuracy:  0.6211340206185567\n","Precision:  0.6357615894039735\n","Recall:  0.5106382978723404\n","F1 Score:  0.5663716814159292\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aOJociinksMh"},"source":["'''\n","Iteration tests on Naive-Bayes\n","'''\n","import statistics\n","\n","extract_method = \"CountVectorizer\"\n","iter_each = 10\n","iter_total = 50\n","m_types = [\"complement\", \"multinomial\"]\n","means = []\n","\n","for model_type in m_types:\n","  for k in range(iter_total):\n","    accuracies = []\n","    smoothing = random.uniform(0.01, 0.8)\n","    for i in range(iter_each):\n","      accuracies.append(NAIVEBAYES_CV(smoothing, model_type))\n","    mean = statistics.mean(accuracies)\n","    print(\"=> Mean:\", mean, \"- Smoothing:\", smoothing, \"- Model:\", model_type)\n","    means.append((mean, smoothing, model_type, extract_method))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPy6GpsT4WRO"},"source":["# from pyspark.sql.types import FloatType\n","# acc_df = pd.DataFrame(means, columns=['mean', 'smoothing', 'model_type', 'extract_method'])\n","# acc_df.to_csv(\"means_countvec.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nz0V5-ELCOZM"},"source":["# from google.colab import files\n","# files.download('means_countvec.csv') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"laqaVwTuFCSa"},"source":[""],"execution_count":null,"outputs":[]}]}