{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project-WallStreetBets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSmCrU8CYLkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07abfceb-07c5-4804-8a60-3954f5fd6e18"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install praw\n",
        "!pip3 install iexfinance"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212.3MB 71kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 19.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=f56cc4c0c07794fec954f44b098c74ad70a198ea0574dafc2344a9b7bdae4a3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n",
            "Collecting praw\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/a8/a2e2d0750ee17c7e3d81e4695a0338ad0b3f231853b8c3fa339ff2d25c7c/praw-7.2.0-py3-none-any.whl (159kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 5.0MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.54.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 5.2MB/s \n",
            "\u001b[?25hCollecting update-checker>=0.18\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
            "Collecting prawcore<3,>=2\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/df/4a9106bea0d26689c4b309da20c926a01440ddaf60c09a5ae22684ebd35f/prawcore-2.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.18->praw) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (1.24.3)\n",
            "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
            "Successfully installed praw-7.2.0 prawcore-2.0.0 update-checker-0.18.0 websocket-client-0.58.0\n",
            "Collecting iexfinance\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/a6/653eb3306789f97f761a7889913923e0e814967a342099d4f11c0604eaa1/iexfinance-0.5.0-py3-none-any.whl (54kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from iexfinance) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from iexfinance) (1.1.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (2020.12.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->iexfinance) (1.15.0)\n",
            "Installing collected packages: iexfinance\n",
            "Successfully installed iexfinance-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV_t_JDlZHAg"
      },
      "source": [
        "from pyspark.rdd import RDD\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql.functions import desc\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark import SparkContext as sc\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "#from iexfinance.stocks import Stock\n",
        "#from iexfinance.stocks import get_historical_data\n",
        "import os\n",
        "# tools\n",
        "import math\n",
        "import json\n",
        "import requests\n",
        "import itertools\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import string\n",
        "# Set IEX Finance API Token for Sandbox test mode\n",
        "os.environ['IEX_API_VERSION'] = 'iexcloud-sandbox'\n",
        "os.environ['IEX_TOKEN'] = ''\n",
        "\n",
        "def init_spark():\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"Python Spark SQL basic example\") \\\n",
        "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "        .getOrCreate()\n",
        "    return spark\n",
        "spark = init_spark()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tEhyuIH2trR"
      },
      "source": [
        "# Print iterations progress\n",
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
        "    \"\"\"\n",
        "    Call in a loop to create terminal progress bar\n",
        "    @params:\n",
        "        iteration   - Required  : current iteration (Int)\n",
        "        total       - Required  : total iterations (Int)\n",
        "        prefix      - Optional  : prefix string (Str)\n",
        "        suffix      - Optional  : suffix string (Str)\n",
        "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
        "        length      - Optional  : character length of bar (Int)\n",
        "        fill        - Optional  : bar fill character (Str)\n",
        "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
        "    \"\"\"\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
        "    # Print New Line on Complete\n",
        "    if iteration == total: \n",
        "        print()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTAG1HhPIZLn"
      },
      "source": [
        "\"\"\"\n",
        "Function to make an HTTP request to the Pushshift API.\n",
        "- max_retry: Nb of times the request is re-tried if failure occurs.\n",
        "- returns: Python object with the content of the request. (index 'data' property)\n",
        "\"\"\"\n",
        "def get_request(uri, max_retry = 5):\n",
        "  def get(uri):\n",
        "    response = requests.get(uri)\n",
        "    assert response.status_code == 200\n",
        "    return json.loads(response.content)\n",
        "  # Retry if request call failed\n",
        "  retry = 1\n",
        "  while retry < max_retry:\n",
        "    try:\n",
        "      response = get(uri)\n",
        "      return response\n",
        "    except:\n",
        "      #print(f\"[{retry}] Request failed, re-trying...\")\n",
        "      # wait 1 second before retry\n",
        "      time.sleep(1)\n",
        "      retry += 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgUPYZ8kni0H",
        "outputId": "2697d70e-e5f7-43ab-ecce-97410b7936d1"
      },
      "source": [
        "# Testing get_request() with test uri. Should return a non-empty Python object.\n",
        "obj = get_request(\"https://httpbin.org/get\")\n",
        "print(obj['url'])\n",
        "# Returning posts from wallstreetbets. The posts are in the \"data\" property of the response.\n",
        "# Use this to check format: https://jsonformatter.curiousconcept.com/#\n",
        "# obj2 = get_request('https://api.pushshift.io/reddit/search/submission?subreddit=wallstreetbets')\n",
        "# print(obj2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://httpbin.org/get\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQkcQb6TnlR_"
      },
      "source": [
        "\"\"\"\n",
        "Gets the all the posts from a given subreddit in the specific time range.\n",
        "- subreddit: name of subreddit\n",
        "- begin: timestamp (in unix) of start date\n",
        "- end: timestamp (in unix) of end date\n",
        "- returns: list of all the posts in the time interval as objects. {id=\"..\", title=\"...\", etc...}\n",
        "\"\"\"\n",
        "def get_posts(subreddit, begin, end):\n",
        "  # Max size of each Pushshift API request is 100 posts.\n",
        "  SIZE = 100\n",
        "  PUSHSHIFT_URI = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}'\n",
        "  nb_requests_made = 1\n",
        "  loading_string = \"LOADING %: [\"\n",
        "  print(\"LOADING %: [\", end=\" \")\n",
        "\n",
        "  # filter the posts data\n",
        "  def filter_posts(uri, begin, end):\n",
        "    full_posts = get_request(uri.format(subreddit, begin, end, SIZE))\n",
        "    if full_posts is None:\n",
        "      raise ValueError(\"Response is empty or none.\")\n",
        "\n",
        "    posts = []\n",
        "    for post in full_posts['data']:\n",
        "      try:\n",
        "        if post['link_flair_text'] and post['link_flair_css_class'] and post['selftext'] and post['selftext'] != \"[removed]\" and post['selftext'] != \"[deleted]\":\n",
        "          posts.append({\\\n",
        "            'id': post['id'],\\\n",
        "            'title': post['title'].translate(str.maketrans('', '', string.punctuation)),\\\n",
        "            'score': post['score'],\\\n",
        "            'upvote_ratio': post['upvote_ratio'],\\\n",
        "            'author': post['author'],\\\n",
        "            'created_utc': post['created_utc'],\\\n",
        "            'flair': post['link_flair_text'],\\\n",
        "            'flaircss': post['link_flair_css_class'],\\\n",
        "            'num_comments': post['num_comments'],\\\n",
        "            'text': post['selftext'].translate(str.maketrans('', '', string.punctuation)),\\\n",
        "            'url': post['url']\\\n",
        "          })\n",
        "      except:\n",
        "        pass\n",
        "    # get timestamp of last post\n",
        "    last_timestamp = full_posts['data'][-1]['created_utc']\n",
        "    posts_amount = len(full_posts['data'])\n",
        "          \n",
        "    #return list(filtered)\n",
        "    return [posts, last_timestamp, posts_amount]\n",
        "\n",
        "  posts_etc = filter_posts(PUSHSHIFT_URI, begin, end)\n",
        "  posts = posts_etc[0]\n",
        "  last_timestamp = posts_etc[1]\n",
        "  posts_amount = posts_etc[2]\n",
        "  # If reached limit of 100 posts retrieved, make request again until 'end' time.\n",
        "  while posts_amount == SIZE:\n",
        "    # Timestamp of the last post we previously retrieved\n",
        "    new_begin = last_timestamp - 10\n",
        "    more_posts_etc = filter_posts(PUSHSHIFT_URI, new_begin, end)\n",
        "    last_timestamp = more_posts_etc[1]\n",
        "    posts_amount = more_posts_etc[2]\n",
        "    posts.extend(more_posts_etc[0])\n",
        "    nb_requests_made += 1\n",
        "    printProgressBar((last_timestamp-begin)//10000 + 1, (end-begin)//10000)\n",
        "    \n",
        "  print(\"Number of requests made: \", nb_requests_made)\n",
        "  return posts"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPfvW-hwvTFh",
        "outputId": "247e0baa-5ed3-4bfb-c46f-613b910b35c0"
      },
      "source": [
        "\"\"\"\n",
        "Retrieve posts\n",
        "- nb_days_from_today: number of days from today you want to retrieve\n",
        "- return: lists of all posts in time interval\n",
        "\"\"\"\n",
        "\n",
        "def retrieve(nb_days_from_today):\n",
        "  end = math.ceil(datetime.utcnow().timestamp())\n",
        "  begin = math.ceil((datetime.utcnow() - timedelta(days=nb_days_from_today)).timestamp())\n",
        "  print(\"Timestamps: \", begin, end)\n",
        "  posts = get_posts('wallstreetbets', begin, end)\n",
        "\n",
        "  unique_posts = np.unique([post['id'] for post in posts])\n",
        "  print(\"Size: \", len(posts))\n",
        "  print(\"Size of uniques: \", len(unique_posts))\n",
        "  print(\"Example posts: \", posts[:5])\n",
        "  return posts\n",
        "\n",
        "# all posts!\n",
        "posts = retrieve(1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timestamps:  1616902145 1616988545\n",
            " |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% \n",
            "Number of requests made:  13\n",
            "Size:  164\n",
            "Size of uniques:  162\n",
            "Example posts:  [{'id': 'metnlc', 'title': 'Tesla Marketing Idea ELON I HOPE YOU SEE THIS', 'score': 1, 'upvote_ratio': 1.0, 'author': 'corona4all', 'created_utc': 1616902459, 'flair': 'Meme', 'flaircss': 'meme', 'num_comments': 0, 'text': 'I was thinking of ways to get this Daddy Elons TSLA Stock to MARS\\n\\nThought this maybe an amazing idea by monetizing on this Cargo Ship Evergreen drama and promoting the Cybertruck that has more angles than a isoceles triangle\\n\\nBon Apetit\\n\\nhttpsimgurcomWFFrcuAhttpsimgurcomWFFrcuA', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/metnlc/tesla_marketing_idea_elon_i_hope_you_see_this/'}, {'id': 'metp1b', 'title': 'When I see US retailer investors talk about taxes', 'score': 1, 'upvote_ratio': 1.0, 'author': 'U-Copy', 'created_utc': 1616902616, 'flair': 'Meme', 'flaircss': 'meme', 'num_comments': 2, 'text': 'ampx200B\\n\\nhttpspreviewredditt6cyx1l0wop61jpgwidth500ampformatpjpgampautowebpampscede3f80770b6a3c0074752d6bff11d9051095eb', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/metp1b/when_i_see_us_retailer_investors_talk_about_taxes/'}, {'id': 'metr3j', 'title': 'So imagine you are the world The Suez Canal is your asshole This ship the Ever Given is the 4th largest dildo man kind has ever created This dildo is now in your asshole and might be there for awhile', 'score': 1, 'upvote_ratio': 1.0, 'author': 'NaticusN', 'created_utc': 1616902854, 'flair': 'Discussion', 'flaircss': 'question', 'num_comments': 27, 'text': 'Letâ€™s talk about tides for the apes who live in trees  This planet we live on has â€œtidesâ€ because it spins commonly called day and night Tides are caused by the moon The moon is one out of two really big things we see in the sky Itâ€™s also where rocket ships live \\n\\nEveryday the tide goes up and down twice to be exact but if you look day to day high tides get higher then peak then come back down again just like your bank account The peak happens on March 31 and again a week later  I worry that if itâ€™s not out by then then we better get ready for that dildo to be the for a bit', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/metr3j/so_imagine_you_are_the_world_the_suez_canal_is/'}, {'id': 'metsxq', 'title': 'BB The size of realworld driving datasets that Blackberry IVY has access to will be so much bigger than Teslas', 'score': 1, 'upvote_ratio': 1.0, 'author': 'Character-Cup-2263', 'created_utc': 1616903060, 'flair': 'DD', 'flaircss': 'dd', 'num_comments': 188, 'text': 'A huge reason for Teslas insane valuation is the fact that Tesla has amassed 3 billion miles of realworld Autopilot data by comparison Waymo only has 20 million realworld miles and 10 billion simulation miles This allows Tesla to be the only automotive company currently that can train visionbased selfdriving system in the real world at such a huge scale Essentially Tesla is utilizing its users as free labor to train its selfdriving system by having the users correct the system whenever it makes a wrong turn\\n\\nBlackberry IVY will very soon change the game By creating a standard data abstraction layer on the 175 million QNXpowered vehicles and possibly more since IVY is OSagnostic and will support other nonQNX vehicles Blackberry IVY will likely become the defacto industry standard for automakers to share normalized sensor data camera radar lidar steering wheel rotation brakes acceleration etc with Autonomous Vehicle software makers Waymo Cruise Argo Motional Aurora TuSimple Baidu PonyAI Momenta etc\\n\\nBy sharing I mean monetizing Deidentified vehicle sensor and localization data will be the most important asset that automakers can monetize in the immediate short term Blackberry and AWS will be the bridge between the traditional automotive world and the software world by creating programming standards interface and data marketplaces\\n\\nJust imagine this Tesla only has lt2 million vehicles on the road currently and they are already called a Big Data company and worldleading selfdriving car company debatable I personally think anything under L4 autonomy is ADAS not selfdriving \\n\\nImagine what Blackberry IVY can help the automakers and AV software makers achieve with normalized data from gt175 million vehicles Blackberry IVY will provide a standardized safe and secure way for AV software makers to tighten the training feedback loop between users and their software as well as validate their systems in realworld scenarios at a much larger scale than Tesla This will save these AV companies a lot of money from operating their own test vehicle fleets in various locations across the world\\n \\nWith the threat of Tesla coming to eat traditional automakers lunches Blackberry IVY will likely create FearOfMissingOuts FOMOs among traditional automakers to adopt IVY as a musthave enterprise software The industrys transition to EVs will inevitably make any competitive advantage developed around combustion engines and mechanical drivetrain obsolete Software will become a key differentiator for cars in the near future especially cloudconnected vehicle datadriven products that improves battery performance ride quality infotainment autonomous driving Any forwardlooking automaker both ICE and EV should already be looking to devote significant amount of their resources into improving their software offerings or risk getting wiped out in the next industry upheaval led by Tesla Getting better tooling and software infrastructure like Blackberry IVY is their first step\\n\\nIVY will very likely be an easy upsell for existing AWS Automotive customers like Toyota BMW VW to further enhance their cloudbased enterprise workflows and product development lifecycle etc Both Blackberry and AWS  have been their trusted technology partners for a very long time and there is no major conflict of interest regarding data ownership unlike Google', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/metsxq/bb_the_size_of_realworld_driving_datasets_that/'}, {'id': 'mettu0', 'title': 'When I see post US retail investors talking about tax', 'score': 1, 'upvote_ratio': 1.0, 'author': 'U-Copy', 'created_utc': 1616903167, 'flair': 'Meme', 'flaircss': 'meme', 'num_comments': 1, 'text': 'ampx200B\\n\\nhttpspreviewreddit5dlemxkpxop61jpgwidth500ampformatpjpgampautowebpamps5c069d6d9b168bc2f4c35742f28aa24a21ca890a\\n\\nhttpspreviewredditmr42ou5qxop61jpgwidth1165ampformatpjpgampautowebpamps98f996f9bb5a43f9879db160a7fc0baadd894467', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/mettu0/when_i_see_post_us_retail_investors_talking_about/'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "tvbLzAGHuHoT",
        "outputId": "f0e98110-49a3-4647-c735-61fa083605e2"
      },
      "source": [
        "\"\"\"\n",
        "OUTPUT TO CSVVVVVVV\n",
        "\n",
        "using RDD and DF\n",
        "\"\"\"\n",
        "posts_rdd = spark.sparkContext.parallelize(posts)\n",
        "posts_rdd = posts_rdd.map(lambda post: Row(id=post['id'], title=post['title'], flair=str(post['flair']), score=post['score'], upvote_ratio=post['upvote_ratio'], author=str(post['author']), num_comments=post['num_comments'], text=post['text'], created=post['created_utc'], url=post['url']))\n",
        "# eliminate duplicates\n",
        "posts_rdd = posts_rdd.distinct()\n",
        "posts_df = spark.createDataFrame(posts_rdd)\n",
        "print(posts_df.count())\n",
        "posts_df.toPandas()\n",
        "\n",
        "# write to csv\n",
        "#posts_df.coalesce(1).write.csv('30daysredditposts.csv', header=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>flair</th>\n",
              "      <th>score</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>author</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>text</th>\n",
              "      <th>created</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metnlc</td>\n",
              "      <td>Tesla Marketing Idea ELON I HOPE YOU SEE THIS</td>\n",
              "      <td>Meme</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>corona4all</td>\n",
              "      <td>0</td>\n",
              "      <td>I was thinking of ways to get this Daddy Elons...</td>\n",
              "      <td>1616902459</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metp1b</td>\n",
              "      <td>When I see US retailer investors talk about taxes</td>\n",
              "      <td>Meme</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>U-Copy</td>\n",
              "      <td>2</td>\n",
              "      <td>ampx200B\\n\\nhttpspreviewredditt6cyx1l0wop61jpg...</td>\n",
              "      <td>1616902616</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mettu0</td>\n",
              "      <td>When I see post US retail investors talking ab...</td>\n",
              "      <td>Meme</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>U-Copy</td>\n",
              "      <td>1</td>\n",
              "      <td>ampx200B\\n\\nhttpspreviewreddit5dlemxkpxop61jpg...</td>\n",
              "      <td>1616903167</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metz4t</td>\n",
              "      <td>BUCKLE UP  we just saw a hedge fund die this w...</td>\n",
              "      <td>DD</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>boneywankenobi</td>\n",
              "      <td>632</td>\n",
              "      <td>Hooo boy I just figured out something amazing ...</td>\n",
              "      <td>1616903745</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>meu4mh</td>\n",
              "      <td>Who like Games</td>\n",
              "      <td>Discussion</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>r_ventura_23</td>\n",
              "      <td>0</td>\n",
              "      <td>I play a game called Kings Age  The US server ...</td>\n",
              "      <td>1616904345</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>mfgfh8</td>\n",
              "      <td>OzscðŸ¤‘ðŸ¤‘ðŸ¤‘</td>\n",
              "      <td>Gain</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Fine_Strength3137</td>\n",
              "      <td>1</td>\n",
              "      <td>Green day tomorrow ðŸš€ðŸš€ðŸš€</td>\n",
              "      <td>1616987305</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>mfggcd</td>\n",
              "      <td>BLDV IS ABOUT TO TAKE OFF ðŸš€ðŸš€</td>\n",
              "      <td>News</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Beautiful_Peanut_721</td>\n",
              "      <td>1</td>\n",
              "      <td>Are you all in yet</td>\n",
              "      <td>1616987396</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>mfggra</td>\n",
              "      <td>Tomorrows Market</td>\n",
              "      <td>Discussion</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>PrestigiousMotor7840</td>\n",
              "      <td>0</td>\n",
              "      <td>It sure would be nice to watch some huge gains...</td>\n",
              "      <td>1616987439</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>mfghqa</td>\n",
              "      <td>Naked puts</td>\n",
              "      <td>Discussion</td>\n",
              "      <td>1</td>\n",
              "      <td>0.99</td>\n",
              "      <td>BipolarSeacrets</td>\n",
              "      <td>0</td>\n",
              "      <td>So Iâ€™m debating on going full reeeee and selli...</td>\n",
              "      <td>1616987552</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>mfgj08</td>\n",
              "      <td>The top is in boys</td>\n",
              "      <td>Meme</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>retry808</td>\n",
              "      <td>12</td>\n",
              "      <td>So I was on the phone with my parents and out ...</td>\n",
              "      <td>1616987682</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                                url\n",
              "0    metnlc  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "1    metp1b  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "2    mettu0  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "3    metz4t  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "4    meu4mh  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "..      ...  ...                                                ...\n",
              "157  mfgfh8  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "158  mfggcd  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "159  mfggra  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "160  mfghqa  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "161  mfgj08  ...  https://www.reddit.com/r/wallstreetbets/commen...\n",
              "\n",
              "[162 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkUgXjRfB9p8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}